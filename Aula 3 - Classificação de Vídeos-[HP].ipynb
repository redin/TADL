{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-24 01:40:59--  https://s3-us-west-2.amazonaws.com/wehrmann/videodata.zip\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.205.0\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.205.0|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21784221 (21M) [application/zip]\n",
      "Saving to: ‘videodata.zip’\n",
      "\n",
      "videodata.zip       100%[===================>]  20,77M  61,4KB/s    in 6m 19s  \n",
      "\n",
      "2019-01-24 01:47:19 (56,2 KB/s) - ‘videodata.zip’ saved [21784221/21784221]\n",
      "\n",
      "Archive:  videodata.zip\n",
      "  inflating: test_videos.npy         \n",
      "  inflating: test_labels.npy         \n",
      "  inflating: train_labels.npy        \n",
      "  inflating: train_videos.npy        \n"
     ]
    }
   ],
   "source": [
    "# Download do dataset\n",
    "import os \n",
    "if not os.path.exists('videodata.zip'):\n",
    "    !wget https://s3-us-west-2.amazonaws.com/wehrmann/videodata.zip\n",
    "    !unzip videodata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLoader(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path='./', data_split='train',):\n",
    "        super(VideoLoader, self).__init__()\n",
    "        self.data = np.load('{}/{}_videos.npy'.format(path, data_split))\n",
    "        self.labels = np.load('{}/{}_labels.npy'.format(path, data_split))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "                \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        video = self.data[index].transpose([0, 2, 3, 1])\n",
    "        x = [self.transform(frame) for frame in video]\n",
    "        x = torch.stack(x, 0)\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        return x, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=VideoLoader(data_split='train'),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=VideoLoader(data_split='test'),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_epoch(\n",
    "        model, \n",
    "        device, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        epoch, \n",
    "        log_interval\n",
    "    ):\n",
    "    model.train()\n",
    "    history = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(\n",
    "        model, \n",
    "        device, \n",
    "        criterion, \n",
    "        test_loader\n",
    "    ):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        device,\n",
    "        lr,\n",
    "        nb_epochs=3,\n",
    "        log_interval=100,\n",
    "    ):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for epoch in range(1, nb_epochs + 1):\n",
    "        print('\\n* * * Training * * *')\n",
    "        train_epoch(\n",
    "            model=model, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            epoch=epoch, \n",
    "            log_interval=log_interval\n",
    "        )\n",
    "        print('\\n* * * Evaluating * * *')\n",
    "        acc = test(model, device, criterion, test_loader)        \n",
    "    \n",
    "    return acc\n",
    "\n",
    "def check_input(model, device):\n",
    "    dummy_data = torch.zeros(5, 3, 1, 28, 28).to(device)\n",
    "    dummy_pred = model(dummy_data)        \n",
    "    assert dummy_pred.shape == (5, 2), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
    "    print('Passed')\n",
    "    return dummy_pred\n",
    "\n",
    "def plot_instances(videos, labels, n_instances=5, n_frames=3):\n",
    "    fig, axes = plt.subplots(n_instances, n_frames)\n",
    "    for i, axs in enumerate(axes):\n",
    "        for j, ax in enumerate(axs):\n",
    "            ax.imshow(videos[i,j].squeeze(), cmap='gray')            \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        ax.text(35, 15, 'Label: {} - {}'.format(labels[i], label_dict[labels[i]]), fontsize=14)\n",
    "\n",
    "label_dict = ['Decrescente', 'Crescente']        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parâmetros que você pode definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device_name = 'cpu'\n",
    "nb_epochs = 3\n",
    "log_interval = 500\n",
    "lr = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferência dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loaders(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  (40000, 3, 1, 28, 28) (40000,)\n",
      "Test size :  (4000, 3, 1, 28, 28) (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Train size: ', \n",
    "    train_loader.dataset.data.shape, \n",
    "    train_loader.dataset.labels.shape\n",
    ")\n",
    "print(\n",
    "    'Test size : ', \n",
    "    test_loader.dataset.data.shape, \n",
    "    test_loader.dataset.labels.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Example:  torch.Size([16, 3, 1, 28, 28]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "videos, labels = next(iter(train_loader))\n",
    "print('Instance Example: ', videos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_instances(videos, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seu trabalho começa aqui:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crie uma rede neural, usando `nn.LSTM()` ou `nn.GRU()` para processar a dimensão temporal. \n",
    "\n",
    "\n",
    "* Utilize a rede DigitsConvNet para processar cada um dos frames. \n",
    "* Utilize uma rede recorrente da sua escolha para processar a dimensão temporal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitsConvNet, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(in_features=3136, out_features=10)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], 64*7*7) # Ou x = x.view(x.shape[0], -1)\n",
    "        #out = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLSTM(nn.Module):\n",
    "    def __init__(self, rnn_units = 64):\n",
    "        super(VideoLSTM, self).__init__()\n",
    "        \n",
    "        # Rede para processamento de cada frame\n",
    "        self.digitscnn = DigitsConvNet()\n",
    "        self.rnn_units = rnn_units\n",
    "        self.rnn = nn.LSTMCell(input_size=3136, hidden_size=self.rnn_units)\n",
    "        self.fc = nn.Linear(self.rnn_units,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, time_steps, channels, h,w = x.shape\n",
    "        x_flat = x.view(batch*time_steps, channels, h,w)\n",
    "        features = self.digitscnn(x_flat)\n",
    "        features = features.view(batch, time_steps, -1)\n",
    "        \n",
    "        hidden_act = torch.zeros(batch, self.rnn_units)\n",
    "        cell_act = torch.zeros(batch, self.rnn_units)\n",
    "        features = features.squeeze(1)\n",
    "        for t in range(time_steps):\n",
    "            xt = features[:,t,:]\n",
    "            (hidden_act, cell_act) = self.rnn(xt, (hidden_act, cell_act))\n",
    "        out = self.fc(hidden_act)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoLSTM(\n",
      "  (digitscnn): DigitsConvNet(\n",
      "    (conv_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (rnn): LSTMCell(3136, 64)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VideoLSTM().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.673219\n",
      "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.249801\n",
      "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.038683\n",
      "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.129727\n",
      "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.011775\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0011, Accuracy: 3982/4000 (99.55%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 2 [0/40000 (0%)]\tLoss: 0.009300\n",
      "Train Epoch: 2 [8000/40000 (20%)]\tLoss: 0.005046\n",
      "Train Epoch: 2 [16000/40000 (40%)]\tLoss: 0.008069\n",
      "Train Epoch: 2 [24000/40000 (60%)]\tLoss: 0.002626\n",
      "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 0.021287\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0004, Accuracy: 3996/4000 (99.90%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 3 [0/40000 (0%)]\tLoss: 0.001011\n",
      "Train Epoch: 3 [8000/40000 (20%)]\tLoss: 0.000582\n",
      "Train Epoch: 3 [16000/40000 (40%)]\tLoss: 0.000463\n",
      "Train Epoch: 3 [24000/40000 (60%)]\tLoss: 0.000446\n",
      "Train Epoch: 3 [32000/40000 (80%)]\tLoss: 0.000670\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0005, Accuracy: 3990/4000 (99.75%)\n",
      "\n",
      "Final acc: 99.75%\n"
     ]
    }
   ],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Atualize sua rede de classificação de vídeos usando uma Rede Recorrente Bidirecional (`nn.LSTM(bidirectional=True)`, `nn.GRU(bidirectional=True`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, rnn_units = 64):\n",
    "        super(BiRNN, self).__init__()\n",
    "        # Rede para processamento de cada frame\n",
    "        self.digitscnn = DigitsConvNet()\n",
    "        self.rnn_units = rnn_units\n",
    "        self.hidden_size=self.rnn_units\n",
    "        self.rnn = nn.LSTM(input_size=3136, hidden_size=self.rnn_units, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(self.rnn_units*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        batch, time_steps, channels, h,w = x.shape\n",
    "        x_flat = x.view(batch*time_steps, channels, h,w)\n",
    "        features = self.digitscnn(x_flat)\n",
    "        features = features.view(batch, time_steps, -1)\n",
    "        out, _ = self.rnn(features, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiRNN(\n",
      "  (digitscnn): DigitsConvNet(\n",
      "    (conv_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (rnn): LSTM(3136, 64, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "model = BiRNN().to(device)\n",
    "print(model)\n",
    "\n",
    "pred = model(torch.zeros(5, 3, 1, 28, 28))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.706670\n",
      "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.242043\n",
      "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.070172\n",
      "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.037908\n",
      "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.029855\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0009, Accuracy: 3994/4000 (99.85%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 2 [0/40000 (0%)]\tLoss: 0.003229\n",
      "Train Epoch: 2 [8000/40000 (20%)]\tLoss: 0.037118\n",
      "Train Epoch: 2 [16000/40000 (40%)]\tLoss: 0.004079\n",
      "Train Epoch: 2 [24000/40000 (60%)]\tLoss: 0.000539\n",
      "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 0.001033\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0006, Accuracy: 3988/4000 (99.70%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 3 [0/40000 (0%)]\tLoss: 0.001763\n",
      "Train Epoch: 3 [8000/40000 (20%)]\tLoss: 0.003529\n",
      "Train Epoch: 3 [16000/40000 (40%)]\tLoss: 0.001724\n",
      "Train Epoch: 3 [24000/40000 (60%)]\tLoss: 0.000125\n",
      "Train Epoch: 3 [32000/40000 (80%)]\tLoss: 0.000303\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0002, Accuracy: 3993/4000 (99.83%)\n",
      "\n",
      "Final acc: 99.83%\n"
     ]
    }
   ],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implemente uma rede neural para classificação de vídeos usando um *global average pooling* para processar a dimensão temporal\n",
    "\n",
    "**OBS: Treine esta rede por apenas 1 época!**\n",
    "\n",
    "Sua rede deve conter uma rede convolucional para processar cada *frame* do vídeo. O processamnto da dimensão temporal deverá ser feito através de um *global average pooling*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPoolNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalPoolNet, self).__init__()\n",
    "        # Rede para processamento de cada frame\n",
    "        self.digitscnn = DigitsConvNet()  \n",
    "        self.fc = nn.Linear(3136,2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, time_steps, channels, h,w = x.shape\n",
    "        x_flat = x.view(batch*time_steps, channels, h,w)\n",
    "        features = self.digitscnn(x_flat)\n",
    "        features = features.view(batch, time_steps, -1)\n",
    "        #print(features.shape)\n",
    "        out = features.mean(1)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Verifique se a saída do seu modelo está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalPoolNet(\n",
      "  (digitscnn): DigitsConvNet(\n",
      "    (conv_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (fc): Linear(in_features=3136, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GlobalPoolNet().to(device)\n",
    "print(model)\n",
    "\n",
    "pred = model(torch.zeros(5, 3, 1, 28, 28).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Treine seu modelo por uma (1) época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.700120\n",
      "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.695184\n",
      "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.692919\n",
      "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.694066\n",
      "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.690363\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0433, Accuracy: 1985/4000 (49.62%)\n",
      "\n",
      "Final acc: 49.62%\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1\n",
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implemente o processamento da dimensão temporal utilizando uma camada de convolução \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoConvNet(nn.Module):\n",
    "    def __init__():\n",
    "        super(VideoConvNet, self).__init__()            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VideoLSTM().to(device)\n",
    "print(model)\n",
    "\n",
    "pred = model(torch.zeros(5, 3, 1, 28, 28))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implemente uma rede de classificação de vídeos utilizando convoluções 3D (`nn.Conv3d()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video3DConvNet(nn.Module):\n",
    "    def __init__():\n",
    "        super(Video3DConvNet, self).__init__()            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Video3DConvNet().to(device)\n",
    "print(model)\n",
    "\n",
    "pred = model(torch.zeros(5, 3, 1, 28, 28))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
