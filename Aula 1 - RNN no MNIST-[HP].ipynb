{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root='../data', \n",
    "            train=True, \n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        ),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root='../data', \n",
    "            train=False, \n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        ),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_epoch(\n",
    "        model, \n",
    "        device, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        epoch, \n",
    "        log_interval\n",
    "    ):\n",
    "    model.train()\n",
    "    history = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(\n",
    "        model, \n",
    "        device, \n",
    "        criterion, \n",
    "        test_loader\n",
    "    ):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        device,\n",
    "        lr,\n",
    "        nb_epochs=3,\n",
    "        log_interval=100,\n",
    "    ):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for epoch in range(1, nb_epochs + 1):\n",
    "        print('\\n* * * Training * * *')\n",
    "        train_epoch(\n",
    "            model=model, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            epoch=epoch, \n",
    "            log_interval=log_interval\n",
    "        )\n",
    "        print('\\n* * * Evaluating * * *')\n",
    "        acc = test(model, device, criterion, test_loader)        \n",
    "    \n",
    "    return acc\n",
    "\n",
    "def check_input(model, device):\n",
    "    dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
    "    dummy_pred = model(dummy_data)        \n",
    "    assert dummy_pred.shape == (5, 10), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
    "    print('Passed')\n",
    "    return dummy_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parâmetros que você pode definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device_name = 'cpu'\n",
    "nb_epochs = 3\n",
    "log_interval = 500\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferência dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loaders(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  torch.Size([60000, 28, 28]) torch.Size([60000])\n",
      "Test size :  torch.Size([10000, 28, 28]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Train size: ', \n",
    "    train_loader.dataset.train_data.shape, \n",
    "    train_loader.dataset.train_labels.shape\n",
    ")\n",
    "print(\n",
    "    'Test size : ', \n",
    "    test_loader.dataset.test_data.shape, \n",
    "    test_loader.dataset.test_labels.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Example:  torch.Size([16, 1, 28, 28]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "instance = next(iter(train_loader))\n",
    "print('Instance Example: ', instance[0].shape, instance[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 5)\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(train_loader.dataset.train_data[i], cmap='gray')\n",
    "    ax.set_title(train_loader.dataset.train_labels[i].item())\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seu trabalho começa aqui:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implemente aqui sua primeira arquitetura com `nn.LSTM()` \n",
    "\n",
    "Sua LSTM deve ser capaz de classificar as imagens do MNIST processando de forma recorrente as linhas ou colunas. Lembre-se que as imagens do MNIST tem apenas 1 canal, isto é, elas são em escala de cinza (e não RBG!). \n",
    "* Spoiler: LSTM com 32 neurônios, atinge ~96% de acurácia em 3 épocas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitsLSTM, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(in_features=3136, out_features=10)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv_1(x)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv_2(x))\n",
    "\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.shape[0], 64*7*7)\n",
    "\n",
    "        out = self.fc(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Verifique se a saída do seu modelo está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "model = DigitsLSTM().to(device)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Treine seu modelo por uma 1 época\n",
    "Valores de acc esperados por época: \n",
    "1. 93.5%\n",
    "2. 94.5%\n",
    "3. 96.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.332049\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.062484\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.193527\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.002025\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.036052\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.097380\n"
     ]
    }
   ],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implemente aqui sua arquitetura com `nn.LSTMCell()` \n",
    "\n",
    "Semelhante à arquitetura anterior, sua LSTM deve processar imagens do MNIST iterando sobre as linhas ou as colunas das imagens. A diferença é que agora você deve implementar utilizando uma nn.LSTMCell(). Para isso, você deverá utilizar um laço de repetição `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsCellLSTM(nn.Module):\n",
    "    def __init__(self, rnn_units = 64):\n",
    "        super(DigitsCellLSTM, self).__init__()\n",
    "        self.rnn_units = rnn_units\n",
    "        self.rnn = nn.LSTMCell(input_size=28, hidden_size=self.rnn_units)\n",
    "        self.fc = nn.Linear(self.rnn_units,10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x = x.squeeze(1)\n",
    "        batch, time_steps, features = x.shape\n",
    "        hidden_act = torch.zeros(batch, self.rnn_units)\n",
    "        cell_act = torch.zeros(batch, self.rnn_units)\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            xt = x[:,t,:]\n",
    "            (hidden_act, cell_act) = self.rnn(xt, (hidden_act, cell_act))\n",
    "        out = self.fc(hidden_act)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DigitsCellLSTM().to(device)\n",
    "#dummy_pred = check_input(model, device)\n",
    "pred = model(torch.zeros(5,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.328046\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.323572\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.444785\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.247328\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.028032\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.025468\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.034672\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.276331\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0082, Accuracy: 9630/10000 (96.30%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.095325\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.472397\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.011955\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.470691\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.199191\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.010940\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.337320\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.265012\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0058, Accuracy: 9718/10000 (97.18%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.007882\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.003206\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.208734\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.091339\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.021666\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.006382\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.010259\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.031799\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0047, Accuracy: 9792/10000 (97.92%)\n",
      "\n",
      "Final acc: 97.92%\n"
     ]
    }
   ],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsCellLSTM(nn.Module):\n",
    "    def __init__(self, rnn_units=64, ):\n",
    "        super(DigitsCellLSTM, self).__init__()\n",
    "        self.rnn_units = rnn_units\n",
    "        self.rnn = nn.LSTMCell(input_size=28, hidden_size=self.rnn_units)\n",
    "        self.fc = nn.Linear(self.rnn_units, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        batch, time_steps, features = x.shape\n",
    "        hidden_act = torch.zeros(batch, self.rnn_units).to(device)\n",
    "        cell_act = torch.zeros(batch, self.rnn_units).to(device)\n",
    "        \n",
    "        for time_step in range(time_steps):\n",
    "            xt = x[:,time_step,:]\n",
    "            (hidden_act, cell_act) = self.rnn(xt, (hidden_act, cell_act))\n",
    "        \n",
    "        out = self.fc(hidden_act)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fique à vontade para testar outras variações das suas arquiteturas para conseguir resultados melhores\n",
    "\n",
    "Ideias: \n",
    "* Aumente o número de camadas na LSTM\n",
    "* Teste GRU\n",
    "* Teste arquiteturas bidirecionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourLSTM(nn.Module):\n",
    "    def __init__():\n",
    "        super(YourLSTM, self).__init__()            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
